
# Source: opentelemetry-demo/charts/grafana/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: opentelemetry-demo-grafana
  annotations:
    harness.io/direct-apply: "true"
    
  namespace: preproddemo
  labels:
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/version: "9.4.7"
spec:
  type: ClusterIP
  ports:
    - name: service
      port: 80
      protocol: TCP
      targetPort: 3000
  selector:
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: opentelemetry-demo
---
# Source: opentelemetry-demo/charts/jaeger/templates/allinone-agent-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: opentelemetry-demo-jaeger-agent
  annotations:
    harness.io/direct-apply: "true"
   
  labels:
    app.kubernetes.io/name: jaeger
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/version: "1.42.0"
    app.kubernetes.io/component: service-agent
spec:
  clusterIP: None
  ports:
    - name: zk-compact-trft
      port: 5775
      protocol: UDP
      targetPort: 0
    - name: config-rest
      port: 5778
      targetPort: 0
    - name: jg-compact-trft
      port: 6831
      protocol: UDP
      targetPort: 0
    - name: jg-binary-trft
      port: 6832
      protocol: UDP
      targetPort: 0
  selector:
    app.kubernetes.io/name: jaeger
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: all-in-one
---
# Source: opentelemetry-demo/charts/jaeger/templates/allinone-collector-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: opentelemetry-demo-jaeger-collector
  annotations:
    harness.io/direct-apply: "true"
    
  labels:
    app.kubernetes.io/name: jaeger
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/version: "1.42.0"
    app.kubernetes.io/component: service-collector
spec:
  clusterIP: None
  ports:
    - name: http-zipkin
      port: 9411
      targetPort: 0
    - name: grpc-http
      port: 14250
      targetPort: 0
    - name: c-tchan-trft
      port: 14267
      targetPort: 0
    - name: http-c-binary-trft
      port: 14268
      targetPort: 0
    - name: otlp-grpc
      port: 4317
      targetPort: 0
    - name: otlp-http
      port: 4318
      targetPort: 0
  selector:
    app.kubernetes.io/name: jaeger
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: all-in-one
---
# Source: opentelemetry-demo/charts/jaeger/templates/allinone-query-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: opentelemetry-demo-jaeger-query
  annotations:
    harness.io/direct-apply: "true"
   
  labels:
    app.kubernetes.io/name: jaeger
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/version: "1.42.0"
    app.kubernetes.io/component: service-query
spec:
  clusterIP: None
  ports:
    - name: http-query
      port: 16686
      targetPort: 16686
    - name: grpc-query
      port: 16685
      targetPort: 16685
  selector:
    app.kubernetes.io/name: jaeger
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: all-in-one
---
# Source: opentelemetry-demo/charts/opentelemetry-collector/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: opentelemetry-demo-otelcol
  annotations:
    harness.io/direct-apply: "true"
   
  labels:
    app.kubernetes.io/name: otelcol
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/version: "0.76.1"
    component: standalone-collector
spec:
  type: ClusterIP
  ports: 
    
    - name: jaeger-compact
      port: 6831
      targetPort: 6831
      protocol: UDP
    - name: jaeger-grpc
      port: 14250
      targetPort: 14250
      protocol: TCP
    - name: jaeger-thrift
      port: 14268
      targetPort: 14268
      protocol: TCP
    - name: metrics
      port: 8888
      targetPort: 8888
      protocol: TCP
    - name: otlp
      port: 4317
      targetPort: 4317
      protocol: TCP
      appProtocol: grpc
    - name: otlp-http
      port: 4318
      targetPort: 4318
      protocol: TCP
    - name: prometheus
      port: 9464
      targetPort: 9464
      protocol: TCP
    - name: zipkin
      port: 9411
      targetPort: 9411
      protocol: TCP
  selector:
    app.kubernetes.io/name: otelcol
    app.kubernetes.io/instance: opentelemetry-demo
    component: standalone-collector
---
# Source: opentelemetry-demo/charts/prometheus/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    component: "server"
    app: prometheus
    release: opentelemetry-demo
    chart: prometheus-20.2.0
    heritage: Helm
  name: opentelemetry-demo-prometheus-server
  annotations:
    harness.io/direct-apply: "true"
   
  namespace: preproddemo
spec:
  ports:
    - name: http
      port: 9090
      protocol: TCP
      targetPort: 9090
  selector:
    component: "server"
    app: prometheus
    release: opentelemetry-demo
  sessionAffinity: None
  type: "ClusterIP"
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: opentelemetry-demo-adservice
  annotations:
    harness.io/direct-apply: "true"
    
  labels:
    
    opentelemetry.io/name: opentelemetry-demo-adservice
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: adservice
    app.kubernetes.io/name: opentelemetry-demo-adservice
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector:
    
    opentelemetry.io/name: opentelemetry-demo-adservice
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: opentelemetry-demo-cartservice
  annotations:
    harness.io/direct-apply: "true"
    
  labels:
    
    opentelemetry.io/name: opentelemetry-demo-cartservice
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: cartservice
    app.kubernetes.io/name: opentelemetry-demo-cartservice
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector:
    
    opentelemetry.io/name: opentelemetry-demo-cartservice
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: opentelemetry-demo-checkoutservice
  annotations:
    harness.io/direct-apply: "true"
   
  labels:
    
    opentelemetry.io/name: opentelemetry-demo-checkoutservice
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: checkoutservice
    app.kubernetes.io/name: opentelemetry-demo-checkoutservice
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  type: NodePort
  ports: 
    - port: 8080
      name: tcp-service
      targetPort: 8080
      nodePort: 30007

  selector:
    
    opentelemetry.io/name: opentelemetry-demo-checkoutservice
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: opentelemetry-demo-currencyservice
  annotations:
    harness.io/direct-apply: "true"
  
  labels:
    
    opentelemetry.io/name: opentelemetry-demo-currencyservice
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: currencyservice
    app.kubernetes.io/name: opentelemetry-demo-currencyservice
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080

  selector:
    
    opentelemetry.io/name: opentelemetry-demo-currencyservice
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: opentelemetry-demo-emailservice
  annotations:
    harness.io/direct-apply: "true"
    
  labels:
    
    opentelemetry.io/name: opentelemetry-demo-emailservice
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: emailservice
    app.kubernetes.io/name: opentelemetry-demo-emailservice
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector:
    
    opentelemetry.io/name: opentelemetry-demo-emailservice
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: opentelemetry-demo-featureflagservice
  annotations:
    harness.io/direct-apply: "true"
  
  labels:
    
    opentelemetry.io/name: opentelemetry-demo-featureflagservice
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: featureflagservice
    app.kubernetes.io/name: opentelemetry-demo-featureflagservice
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  type: ClusterIP
  ports:
    - port: 50053
      name: grpc
      targetPort: 50053
    - port: 8081
      name: http
      targetPort: 8081
  selector:
    
    opentelemetry.io/name: opentelemetry-demo-featureflagservice
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: opentelemetry-demo-ffspostgres
  annotations:
    harness.io/direct-apply: "true"
    
  labels:
    
    opentelemetry.io/name: opentelemetry-demo-ffspostgres
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: ffspostgres
    app.kubernetes.io/name: opentelemetry-demo-ffspostgres
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  type: ClusterIP
  ports:
    - port: 5432
      name: postgres
      targetPort: 5432
  selector:
    
    opentelemetry.io/name: opentelemetry-demo-ffspostgres
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: opentelemetry-demo-frontend
  annotations:
    harness.io/direct-apply: "true"
   
  labels:
    
    opentelemetry.io/name: opentelemetry-demo-frontend
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: frontend
    app.kubernetes.io/name: opentelemetry-demo-frontend
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  type: NodePort
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
      nodePort: 30003
  selector:
    
    opentelemetry.io/name: opentelemetry-demo-frontend


---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: opentelemetry-demo-kafka
  annotations:
    harness.io/direct-apply: "true"
    
  labels:
    
    opentelemetry.io/name: opentelemetry-demo-kafka
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: kafka
    app.kubernetes.io/name: opentelemetry-demo-kafka
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  type: ClusterIP
  ports:
    - port: 9092
      name: plaintext
      targetPort: 9092
    - port: 9093
      name: controller
      targetPort: 9093
  selector:
    
    opentelemetry.io/name: opentelemetry-demo-kafka
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: opentelemetry-demo-loadgenerator
  annotations:
    harness.io/direct-apply: "true"
   
  labels:
    
    opentelemetry.io/name: opentelemetry-demo-loadgenerator
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: loadgenerator
    app.kubernetes.io/name: opentelemetry-demo-loadgenerator
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  type: ClusterIP
  ports:
    - port: 8089
      name: tcp-service
      targetPort: 8089
  selector:
    
    opentelemetry.io/name: opentelemetry-demo-loadgenerator
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: opentelemetry-demo-paymentservice
  annotations:
    harness.io/direct-apply: "true"
   
  labels:
    
    opentelemetry.io/name: opentelemetry-demo-paymentservice
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: paymentservice
    app.kubernetes.io/name: opentelemetry-demo-paymentservice
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector:
    
    opentelemetry.io/name: opentelemetry-demo-paymentservice
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: opentelemetry-demo-productcatalogservice
  annotations:
    harness.io/direct-apply: "true"
   
  labels:
    
    opentelemetry.io/name: opentelemetry-demo-productcatalogservice
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: productcatalogservice
    app.kubernetes.io/name: opentelemetry-demo-productcatalogservice
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  type: NodePort
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
      nodePort: 30001
  selector:
    
    opentelemetry.io/name: opentelemetry-demo-productcatalogservice
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: opentelemetry-demo-quoteservice
  annotations:
    harness.io/direct-apply: "true"
   
  labels:
    
    opentelemetry.io/name: opentelemetry-demo-quoteservice
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: quoteservice
    app.kubernetes.io/name: opentelemetry-demo-quoteservice
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector:
    
    opentelemetry.io/name: opentelemetry-demo-quoteservice
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: opentelemetry-demo-recommendationservice
  annotations:
    harness.io/direct-apply: "true"
  labels:
    
    opentelemetry.io/name: opentelemetry-demo-recommendationservice
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: recommendationservice
    app.kubernetes.io/name: opentelemetry-demo-recommendationservice
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector:
    
    opentelemetry.io/name: opentelemetry-demo-recommendationservice
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: opentelemetry-demo-redis
  annotations:
    harness.io/direct-apply: "true"
  labels:
    
    opentelemetry.io/name: opentelemetry-demo-redis
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: redis
    app.kubernetes.io/name: opentelemetry-demo-redis
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  type: ClusterIP
  ports:
    - port: 6379
      name: redis
      targetPort: 6379
  selector:
    
    opentelemetry.io/name: opentelemetry-demo-redis
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: opentelemetry-demo-shippingservice
  annotations:
    harness.io/direct-apply: "true"
  labels:
    
    opentelemetry.io/name: opentelemetry-demo-shippingservice
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: shippingservice
    app.kubernetes.io/name: opentelemetry-demo-shippingservice
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector:
    
    opentelemetry.io/name: opentelemetry-demo-shippingservice
---
# Source: opentelemetry-demo/charts/grafana/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: opentelemetry-demo-grafana
  annotations:
    harness.io/direct-apply: "true"
    harness.io/track: "canary"
  namespace: preproddemo
  labels:
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/version: "9.4.7"
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app.kubernetes.io/name: grafana
      app.kubernetes.io/instance: opentelemetry-demo
  strategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        app.kubernetes.io/name: grafana
        app.kubernetes.io/instance: opentelemetry-demo
      annotations:
        checksum/config: 46e9428a9c36c5c45a84485e747d9911e5d9cc320ac4bec997c39688cfda1b43
        checksum/dashboards-json-config: 01ba4719c80b6fe911b091a7c05124b64eeece964e09c058ef8f9805daca546b
        checksum/sc-dashboard-provider-config: 01ba4719c80b6fe911b091a7c05124b64eeece964e09c058ef8f9805daca546b
        checksum/secret: 168eac9549c1155906143bae680e232ce7a8acecd06af6a8ca9d6088db7473f2
        harness.io/direct-apply: "true"
    spec:
      
      serviceAccountName: opentelemetry-demo-grafana
      automountServiceAccountToken: true
      securityContext:
        fsGroup: 472
        runAsGroup: 472
        runAsUser: 472
      enableServiceLinks: true
      containers:
        - name: grafana
          image: "grafana/grafana:9.4.7"
          imagePullPolicy: IfNotPresent
          volumeMounts:
            - name: config
              mountPath: "/etc/grafana/grafana.ini"
              subPath: grafana.ini
            - name: storage
              mountPath: "/var/lib/grafana"
            - name: dashboards-default
              mountPath: "/var/lib/grafana/dashboards/default"
            - name: config
              mountPath: "/etc/grafana/provisioning/datasources/datasources.yaml"
              subPath: "datasources.yaml"
            - name: config
              mountPath: "/etc/grafana/provisioning/dashboards/dashboardproviders.yaml"
              subPath: "dashboardproviders.yaml"
          ports:
            - name: grafana
              containerPort: 3000
              protocol: TCP
            - name: gossip-tcp
              containerPort: 9094
              protocol: TCP
            - name: gossip-udp
              containerPort: 9094
              protocol: UDP
          env:
            - name: POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: GF_SECURITY_ADMIN_USER
              valueFrom:
                secretKeyRef:
                  name: opentelemetry-demo-grafana
                  key: admin-user
            - name: GF_SECURITY_ADMIN_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: opentelemetry-demo-grafana
                  key: admin-password
            - name: GF_PATHS_DATA
              value: /var/lib/grafana/
            - name: GF_PATHS_LOGS
              value: /var/log/grafana
            - name: GF_PATHS_PLUGINS
              value: /var/lib/grafana/plugins
            - name: GF_PATHS_PROVISIONING
              value: /etc/grafana/provisioning
          livenessProbe:
            failureThreshold: 10
            httpGet:
              path: /api/health
              port: 3000
            initialDelaySeconds: 60
            timeoutSeconds: 30
          readinessProbe:
            httpGet:
              path: /api/health
              port: 3000
          resources:
            limits:
              memory: 500Mi
      volumes:
        - name: config
          configMap:
            name: opentelemetry-demo-grafana
        - name: dashboards-default
          configMap:
            name: opentelemetry-demo-grafana-dashboards
        - name: storage
          emptyDir: {}
---
# Source: opentelemetry-demo/charts/jaeger/templates/allinone-deploy.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: opentelemetry-demo-jaeger
  annotations:
    harness.io/direct-apply: "true"
    harness.io/track: "canary"
  labels:
    app.kubernetes.io/name: jaeger
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/version: "1.42.0"
    app.kubernetes.io/component: all-in-one
    prometheus.io/port: "14269"
    prometheus.io/scrape: "true"
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
      app.kubernetes.io/name: jaeger
      app.kubernetes.io/instance: opentelemetry-demo
      app.kubernetes.io/component: all-in-one
  template:
    metadata:
      labels:
        app.kubernetes.io/name: jaeger
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: all-in-one
      annotations:
        prometheus.io/port: "14269"
        prometheus.io/scrape: "true"
        harness.io/direct-apply: "true"
    spec:
      containers:
        - env:
            - name: METRICS_STORAGE_TYPE
              value: prometheus
            - name: SPAN_STORAGE_TYPE
              value: memory
            - name: COLLECTOR_ZIPKIN_HOST_PORT
              value: :9411
            - name: JAEGER_DISABLED
              value: "false"
            - name: COLLECTOR_OTLP_ENABLED
              value: "true"
          image: jaegertracing/all-in-one:1.42.0
          imagePullPolicy: IfNotPresent
          name: jaeger
          args:
            - "--memory.max-traces"
            - "10000"
            - "--query.base-path"
            - "/jaeger/ui"
            - "--prometheus.server-url"
            - "http://opentelemetry-demo-prometheus-server:9090"
          ports:
            - containerPort: 5775
              protocol: UDP
            - containerPort: 6831
              protocol: UDP
            - containerPort: 6832
              protocol: UDP
            - containerPort: 5778
              protocol: TCP
            - containerPort: 16686
              protocol: TCP
            - containerPort: 16685
              protocol: TCP
            - containerPort: 9411
              protocol: TCP
            - containerPort: 4317
              protocol: TCP
            - containerPort: 4318
              protocol: TCP
          livenessProbe:
            failureThreshold: 5
            httpGet:
              path: /
              port: 14269
              scheme: HTTP
            initialDelaySeconds: 5
            periodSeconds: 15
            successThreshold: 1
            timeoutSeconds: 1
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: 14269
              scheme: HTTP
            initialDelaySeconds: 1
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            limits:
              memory: 500Mi
      serviceAccountName: opentelemetry-demo-jaeger
---
# Source: opentelemetry-demo/charts/opentelemetry-collector/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: opentelemetry-demo-otelcol
  annotations:
    harness.io/direct-apply: "true"
    harness.io/track: "canary | stable"
  labels:
    app.kubernetes.io/name: otelcol
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/version: "0.76.1"
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app.kubernetes.io/name: otelcol
      app.kubernetes.io/instance: opentelemetry-demo
      component: standalone-collector
  strategy:
    type: RollingUpdate
  template:
    metadata:
      annotations:
        checksum/config: 43d3318bb84ce994167ce160b46e0e06eb17a17b8de61b578bf4a3e97f4dcdd1
        opentelemetry_community_demo: "true"
        prometheus.io/port: "9464"
        prometheus.io/scrape: "true"
        harness.io/direct-apply: "true"
      labels:
        app.kubernetes.io/name: otelcol
        app.kubernetes.io/instance: opentelemetry-demo
        component: standalone-collector
        
    spec:
      
      serviceAccountName: opentelemetry-demo-otelcol
      securityContext:
        {}
      containers:
        - name: opentelemetry-collector
          command:
            - /otelcol-contrib
            - --config=/conf/relay.yaml
          securityContext:
            {}
          image: "otel/opentelemetry-collector-contrib:0.76.1"
          imagePullPolicy: IfNotPresent
          ports:
            - name: jaeger-compact
              containerPort: 6831
              protocol: UDP
            - name: jaeger-grpc
              containerPort: 14250
              protocol: TCP
            - name: jaeger-thrift
              containerPort: 14268
              protocol: TCP
            - name: metrics
              containerPort: 8888
              protocol: TCP
            - name: otlp
              containerPort: 4317
              protocol: TCP
            - name: otlp-http
              containerPort: 4318
              protocol: TCP
            - name: prometheus
              containerPort: 9464
              protocol: TCP
            - name: zipkin
              containerPort: 9411
              protocol: TCP
          env:
            - name: MY_POD_IP
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: status.podIP
          livenessProbe:
            httpGet:
              path: /
              port: 13133
          readinessProbe:
            httpGet:
              path: /
              port: 13133
          resources:
            limits:
              memory: 325Mi
          volumeMounts:
            - mountPath: /conf
              name: opentelemetry-collector-configmap
      volumes:
        - name: opentelemetry-collector-configmap
          configMap:
            name: opentelemetry-demo-otelcol
            items:
              - key: relay
                path: relay.yaml
      hostNetwork: false
---
# Source: opentelemetry-demo/charts/prometheus/templates/deploy.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    component: "server"
    app: prometheus
    release: opentelemetry-demo
    chart: prometheus-20.2.0
    heritage: Helm
  name: opentelemetry-demo-prometheus-server
  annotations:
    harness.io/direct-apply: "true"
    harness.io/track: "canary | stable"
  namespace: preproddemo
spec:
  selector:
    matchLabels:
      component: "server"
      app: prometheus
      release: opentelemetry-demo
  replicas: 1
  strategy:
    type: Recreate
    rollingUpdate: null
  template:
    metadata:
      labels:
        component: "server"
        app: prometheus
        release: opentelemetry-demo
        chart: prometheus-20.2.0
        heritage: Helm
    spec:
      enableServiceLinks: true
      serviceAccountName: opentelemetry-demo-prometheus-server
      containers:

        - name: prometheus-server
          image: "quay.io/prometheus/prometheus:v2.43.0"
          imagePullPolicy: "IfNotPresent"
          args:
            - --storage.tsdb.retention.time=15d
            - --config.file=/etc/config/prometheus.yml
            - --storage.tsdb.path=/data
            - --web.console.libraries=/etc/prometheus/console_libraries
            - --web.console.templates=/etc/prometheus/consoles
            - --enable-feature=exemplar-storage
          ports:
            - containerPort: 9090
          readinessProbe:
            httpGet:
              path: /-/ready
              port: 9090
              scheme: HTTP
            initialDelaySeconds: 30
            periodSeconds: 5
            timeoutSeconds: 4
            failureThreshold: 3
            successThreshold: 1
          livenessProbe:
            httpGet:
              path: /-/healthy
              port: 9090
              scheme: HTTP
            initialDelaySeconds: 30
            periodSeconds: 15
            timeoutSeconds: 10
            failureThreshold: 3
            successThreshold: 1
          resources:
            limits:
              memory: 500Mi
          volumeMounts:
            - name: config-volume
              mountPath: /etc/config
            - name: storage-volume
              mountPath: /data
              subPath: ""
      dnsPolicy: ClusterFirst
      securityContext:
        fsGroup: 65534
        runAsGroup: 65534
        runAsNonRoot: true
        runAsUser: 65534
      terminationGracePeriodSeconds: 300
      volumes:
        - name: config-volume
          configMap:
            name: opentelemetry-demo-prometheus-server
        - name: storage-volume
          emptyDir:
            {}
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: opentelemetry-demo-accountingservice
  annotations:
    harness.io/direct-apply: "true"
    harness.io/track: "canary | stable"
  labels:
    
    opentelemetry.io/name: opentelemetry-demo-accountingservice
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: accountingservice
    app.kubernetes.io/name: opentelemetry-demo-accountingservice
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  selector:
    matchLabels:
      
      opentelemetry.io/name: opentelemetry-demo-accountingservice
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: opentelemetry-demo-accountingservice
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: accountingservice
        app.kubernetes.io/name: opentelemetry-demo-accountingservice
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: accountingservice
          image: 'habib1234/accountingservice:latest'
          imagePullPolicy: IfNotPresent
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_K8S_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: OTEL_K8S_NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          - name: OTEL_K8S_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: OTEL_K8S_POD_UID
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.uid
          - name: OTEL_COLLECTOR_NAME
            value: 'opentelemetry-demo-otelcol'
          - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
            value: cumulative
          - name: KAFKA_SERVICE_ADDR
            value: 'opentelemetry-demo-kafka:9092'
          - name: OTEL_EXPORTER_OTLP_ENDPOINT
            value: http://$(OTEL_COLLECTOR_NAME):4317
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: service.name=$(OTEL_SERVICE_NAME),service.instance.id=$(OTEL_K8S_POD_UID),service.namespace=opentelemetry-demo,k8s.namespace.name=$(OTEL_K8S_NAMESPACE),k8s.node.name=$(OTEL_K8S_NODE_NAME),k8s.pod.name=$(OTEL_K8S_POD_NAME)
          resources:
            limits:
              memory: 220Mi
      initContainers:
        - command:
          - sh
          - -c
          - until nc -z -v -w30 opentelemetry-demo-kafka 9092; do echo waiting
            for kafka; sleep 2; done;
          image: busybox:latest
          name: wait-for-kafka
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: opentelemetry-demo-adservice
  annotations:
    harness.io/direct-apply: "true"
    harness.io/track: "canary | stable"
  labels:
    
    opentelemetry.io/name: opentelemetry-demo-adservice
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: adservice
    app.kubernetes.io/name: opentelemetry-demo-adservice
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  selector:
    matchLabels:
      
      opentelemetry.io/name: opentelemetry-demo-adservice
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: opentelemetry-demo-adservice
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: adservice
        app.kubernetes.io/name: opentelemetry-demo-adservice
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: adservice
          image: 'ghcr.io/open-telemetry/demo:1.4.0-adservice'
          imagePullPolicy: IfNotPresent
          ports:
          
          - containerPort: 8080
            name: service
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_K8S_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: OTEL_K8S_NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          - name: OTEL_K8S_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: OTEL_K8S_POD_UID
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.uid
          - name: OTEL_COLLECTOR_NAME
            value: 'opentelemetry-demo-otelcol'
          - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
            value: cumulative
          - name: AD_SERVICE_PORT
            value: "8080"
          - name: FEATURE_FLAG_GRPC_SERVICE_ADDR
            value: 'opentelemetry-demo-featureflagservice:50053'
          - name: OTEL_EXPORTER_OTLP_ENDPOINT
            value: http://$(OTEL_COLLECTOR_NAME):4317
          - name: OTLP_LOGS_EXPORTER
            value: otlp
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: service.name=$(OTEL_SERVICE_NAME),service.instance.id=$(OTEL_K8S_POD_UID),service.namespace=opentelemetry-demo,k8s.namespace.name=$(OTEL_K8S_NAMESPACE),k8s.node.name=$(OTEL_K8S_NODE_NAME),k8s.pod.name=$(OTEL_K8S_POD_NAME)
          resources:
            limits:
              memory: 500Mi
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: opentelemetry-demo-cartservice
  annotations:
    harness.io/direct-apply: "true"
    harness.io/track: "canary | stable"
  
  labels:
    
    opentelemetry.io/name: opentelemetry-demo-cartservice
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: cartservice
    app.kubernetes.io/name: opentelemetry-demo-cartservice
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  selector:
    matchLabels:
      
      opentelemetry.io/name: opentelemetry-demo-cartservice
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: opentelemetry-demo-cartservice
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: cartservice
        app.kubernetes.io/name: opentelemetry-demo-cartservice
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: cartservice
          image: 'ghcr.io/open-telemetry/demo:1.4.0-cartservice'
          imagePullPolicy: IfNotPresent
          ports:
          
          - containerPort: 8080
            name: service
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_K8S_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: OTEL_K8S_NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          - name: OTEL_K8S_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: OTEL_K8S_POD_UID
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.uid
          - name: OTEL_COLLECTOR_NAME
            value: 'opentelemetry-demo-otelcol'
          - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
            value: cumulative
          - name: CART_SERVICE_PORT
            value: "8080"
          - name: ASPNETCORE_URLS
            value: http://*:$(CART_SERVICE_PORT)
          - name: REDIS_ADDR
            value: 'opentelemetry-demo-redis:6379'
          - name: OTEL_EXPORTER_OTLP_ENDPOINT
            value: http://$(OTEL_COLLECTOR_NAME):4317
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: service.name=$(OTEL_SERVICE_NAME),service.instance.id=$(OTEL_K8S_POD_UID),service.namespace=opentelemetry-demo,k8s.namespace.name=$(OTEL_K8S_NAMESPACE),k8s.node.name=$(OTEL_K8S_NODE_NAME),k8s.pod.name=$(OTEL_K8S_POD_NAME)
          resources:
            limits:
              memory: 360Mi
      initContainers:
        - command:
          - sh
          - -c
          - until nc -z -v -w30 opentelemetry-demo-redis 6379; do echo waiting
            for redis; sleep 2; done;
          image: busybox:latest
          name: wait-for-redis
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: opentelemetry-demo-checkoutservice
  annotations:
    harness.io/direct-apply: "true"
    harness.io/track: "canary | stable"
  labels:
    
    opentelemetry.io/name: opentelemetry-demo-checkoutservice
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: checkoutservice
    app.kubernetes.io/name: opentelemetry-demo-checkoutservice
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  selector:
    matchLabels:
      
      opentelemetry.io/name: opentelemetry-demo-checkoutservice
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: opentelemetry-demo-checkoutservice
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: checkoutservice
        app.kubernetes.io/name: opentelemetry-demo-checkoutservice
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: checkoutservice
          image: 'ghcr.io/open-telemetry/demo:1.4.0-checkoutservice'
          imagePullPolicy: IfNotPresent
          ports:
          
          - containerPort: 8080
            name: service
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_K8S_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: OTEL_K8S_NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          - name: OTEL_K8S_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: OTEL_K8S_POD_UID
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.uid
          - name: OTEL_COLLECTOR_NAME
            value: 'opentelemetry-demo-otelcol'
          - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
            value: cumulative
          - name: CHECKOUT_SERVICE_PORT
            value: "8080"
          - name: CART_SERVICE_ADDR
            value: 'opentelemetry-demo-cartservice:8080'
          - name: CURRENCY_SERVICE_ADDR
            value: 'opentelemetry-demo-currencyservice:8080'
          - name: EMAIL_SERVICE_ADDR
            value: http://opentelemetry-demo-emailservice:8080
          - name: PAYMENT_SERVICE_ADDR
            value: 'opentelemetry-demo-paymentservice:8080'
          - name: PRODUCT_CATALOG_SERVICE_ADDR
            value: 'opentelemetry-demo-productcatalogservice:8080'
          - name: SHIPPING_SERVICE_ADDR
            value: 'opentelemetry-demo-shippingservice:8080'
          - name: KAFKA_SERVICE_ADDR
            value: 'opentelemetry-demo-kafka:9092'
          - name: OTEL_EXPORTER_OTLP_ENDPOINT
            value: http://$(OTEL_COLLECTOR_NAME):4317
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: service.name=$(OTEL_SERVICE_NAME),service.instance.id=$(OTEL_K8S_POD_UID),service.namespace=opentelemetry-demo,k8s.namespace.name=$(OTEL_K8S_NAMESPACE),k8s.node.name=$(OTEL_K8S_NODE_NAME),k8s.pod.name=$(OTEL_K8S_POD_NAME)
          resources:
            limits:
              memory: 220Mi
      initContainers:
        - command:
          - sh
          - -c
          - until nc -z -v -w30 opentelemetry-demo-kafka 9092; do echo waiting
            for kafka; sleep 2; done;
          image: busybox:latest
          name: wait-for-kafka
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: opentelemetry-demo-currencyservice
  annotations:
    harness.io/direct-apply: "true"
    harness.io/track: "canary | stable"
  labels:
    
    opentelemetry.io/name: opentelemetry-demo-currencyservice
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: currencyservice
    app.kubernetes.io/name: opentelemetry-demo-currencyservice
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  selector:
    matchLabels:
      
      opentelemetry.io/name: opentelemetry-demo-currencyservice
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: opentelemetry-demo-currencyservice
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: currencyservice
        app.kubernetes.io/name: opentelemetry-demo-currencyservice
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: currencyservice
          image: 'ghcr.io/open-telemetry/demo:1.4.0-currencyservice'
          imagePullPolicy: IfNotPresent
          ports:
          
          - containerPort: 8080
            name: service
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_K8S_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: OTEL_K8S_NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          - name: OTEL_K8S_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: OTEL_K8S_POD_UID
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.uid
          - name: OTEL_COLLECTOR_NAME
            value: 'opentelemetry-demo-otelcol'
          - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
            value: cumulative
          - name: CURRENCY_SERVICE_PORT
            value: "8080"
          - name: OTEL_EXPORTER_OTLP_ENDPOINT
            value: http://$(OTEL_COLLECTOR_NAME):4317
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: service.name=$(OTEL_SERVICE_NAME),service.instance.id=$(OTEL_K8S_POD_UID),service.namespace=opentelemetry-demo,k8s.namespace.name=$(OTEL_K8S_NAMESPACE),k8s.node.name=$(OTEL_K8S_NODE_NAME),k8s.pod.name=$(OTEL_K8S_POD_NAME)
          resources:
            limits:
              memory: 220Mi
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: opentelemetry-demo-emailservice
  annotations:
    harness.io/direct-apply: "true"
    harness.io/track: "canary | stable"
  labels:
    
    opentelemetry.io/name: opentelemetry-demo-emailservice
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: emailservice
    app.kubernetes.io/name: opentelemetry-demo-emailservice
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  selector:
    matchLabels:
      
      opentelemetry.io/name: opentelemetry-demo-emailservice
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: opentelemetry-demo-emailservice
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: emailservice
        app.kubernetes.io/name: opentelemetry-demo-emailservice
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: emailservice
          image: 'ghcr.io/open-telemetry/demo:1.4.0-emailservice'
          imagePullPolicy: IfNotPresent
          ports:
          
          - containerPort: 8080
            name: service
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_K8S_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: OTEL_K8S_NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          - name: OTEL_K8S_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: OTEL_K8S_POD_UID
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.uid
          - name: OTEL_COLLECTOR_NAME
            value: 'opentelemetry-demo-otelcol'
          - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
            value: cumulative
          - name: EMAIL_SERVICE_PORT
            value: "8080"
          - name: APP_ENV
            value: production
          - name: OTEL_EXPORTER_OTLP_TRACES_ENDPOINT
            value: http://$(OTEL_COLLECTOR_NAME):4318/v1/traces
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: service.name=$(OTEL_SERVICE_NAME),service.instance.id=$(OTEL_K8S_POD_UID),service.namespace=opentelemetry-demo,k8s.namespace.name=$(OTEL_K8S_NAMESPACE),k8s.node.name=$(OTEL_K8S_NODE_NAME),k8s.pod.name=$(OTEL_K8S_POD_NAME)
          resources:
            limits:
              memory: 300Mi
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: opentelemetry-demo-featureflagservice
  annotations:
    harness.io/direct-apply: "true"
    harness.io/track: "canary | stable"
  labels:
    
    opentelemetry.io/name: opentelemetry-demo-featureflagservice
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: featureflagservice
    app.kubernetes.io/name: opentelemetry-demo-featureflagservice
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  selector:
    matchLabels:
      
      opentelemetry.io/name: opentelemetry-demo-featureflagservice
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: opentelemetry-demo-featureflagservice
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: featureflagservice
        app.kubernetes.io/name: opentelemetry-demo-featureflagservice
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: featureflagservice
          image: 'ghcr.io/open-telemetry/demo:1.4.0-featureflagservice'
          imagePullPolicy: IfNotPresent
          ports:
          
          - containerPort: 50053
            name: grpc
          - containerPort: 8081
            name: http
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_K8S_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: OTEL_K8S_NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          - name: OTEL_K8S_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: OTEL_K8S_POD_UID
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.uid
          - name: OTEL_COLLECTOR_NAME
            value: 'opentelemetry-demo-otelcol'
          - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
            value: cumulative
          - name: FEATURE_FLAG_SERVICE_PORT
            value: "8081"
          - name: FEATURE_FLAG_GRPC_SERVICE_PORT
            value: "50053"
          - name: DATABASE_URL
            value: ecto://ffs:ffs@opentelemetry-demo-ffspostgres:5432/ffs
          - name: OTEL_EXPORTER_OTLP_ENDPOINT
            value: http://$(OTEL_COLLECTOR_NAME):4317
          - name: OTEL_EXPORTER_OTLP_TRACES_PROTOCOL
            value: grpc
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: service.name=$(OTEL_SERVICE_NAME),service.instance.id=$(OTEL_K8S_POD_UID),service.namespace=opentelemetry-demo,k8s.namespace.name=$(OTEL_K8S_NAMESPACE),k8s.node.name=$(OTEL_K8S_NODE_NAME),k8s.pod.name=$(OTEL_K8S_POD_NAME)
          resources:
            limits:
              memory: 375Mi
          livenessProbe:
            httpGet:
              path: /featureflags/
              port: 8081
            initialDelaySeconds: 30
            periodSeconds: 10
      initContainers:
        - command:
          - sh
          - -c
          - until nc -z -v -w30 opentelemetry-demo-ffspostgres 5432; do echo
            waiting for ffspostgres; sleep 2; done
          image: busybox:latest
          name: wait-for-ffspostgres
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: opentelemetry-demo-ffspostgres
  annotations:
    harness.io/direct-apply: "true"
    harness.io/track: "canary | stable"
  labels:
    
    opentelemetry.io/name: opentelemetry-demo-ffspostgres
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: ffspostgres
    app.kubernetes.io/name: opentelemetry-demo-ffspostgres
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  selector:
    matchLabels:
      
      opentelemetry.io/name: opentelemetry-demo-ffspostgres
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: opentelemetry-demo-ffspostgres
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: ffspostgres
        app.kubernetes.io/name: opentelemetry-demo-ffspostgres
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: ffspostgres
          image: 'postgres:14'
          imagePullPolicy: IfNotPresent
          ports:
          
          - containerPort: 5432
            name: postgres
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_K8S_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: OTEL_K8S_NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          - name: OTEL_K8S_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: OTEL_K8S_POD_UID
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.uid
          - name: OTEL_COLLECTOR_NAME
            value: 'opentelemetry-demo-otelcol'
          - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
            value: cumulative
          - name: POSTGRES_DB
            value: ffs
          - name: POSTGRES_USER
            value: ffs
          - name: POSTGRES_PASSWORD
            value: ffs
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: service.name=$(OTEL_SERVICE_NAME),service.instance.id=$(OTEL_K8S_POD_UID),service.namespace=opentelemetry-demo,k8s.namespace.name=$(OTEL_K8S_NAMESPACE),k8s.node.name=$(OTEL_K8S_NODE_NAME),k8s.pod.name=$(OTEL_K8S_POD_NAME)
          resources:
            limits:
              memory: 320Mi
          securityContext:
            runAsGroup: 999
            runAsNonRoot: true
            runAsUser: 999
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: opentelemetry-demo-frauddetectionservice
  annotations:
    harness.io/direct-apply: "true"
    harness.io/track: "canary | stable"
  labels:
    
    opentelemetry.io/name: opentelemetry-demo-frauddetectionservice
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: frauddetectionservice
    app.kubernetes.io/name: opentelemetry-demo-frauddetectionservice
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  selector:
    matchLabels:
      
      opentelemetry.io/name: opentelemetry-demo-frauddetectionservice
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: opentelemetry-demo-frauddetectionservice
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: frauddetectionservice
        app.kubernetes.io/name: opentelemetry-demo-frauddetectionservice
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: frauddetectionservice
          image: 'ghcr.io/open-telemetry/demo:1.4.0-frauddetectionservice'
          imagePullPolicy: IfNotPresent
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_K8S_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: OTEL_K8S_NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          - name: OTEL_K8S_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: OTEL_K8S_POD_UID
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.uid
          - name: OTEL_COLLECTOR_NAME
            value: 'opentelemetry-demo-otelcol'
          - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
            value: cumulative
          - name: KAFKA_SERVICE_ADDR
            value: 'opentelemetry-demo-kafka:9092'
          - name: OTEL_EXPORTER_OTLP_ENDPOINT
            value: http://$(OTEL_COLLECTOR_NAME):4317
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: service.name=$(OTEL_SERVICE_NAME),service.instance.id=$(OTEL_K8S_POD_UID),service.namespace=opentelemetry-demo,k8s.namespace.name=$(OTEL_K8S_NAMESPACE),k8s.node.name=$(OTEL_K8S_NODE_NAME),k8s.pod.name=$(OTEL_K8S_POD_NAME)
          resources:
            limits:
              memory: 400Mi
      initContainers:
        - command:
          - sh
          - -c
          - until nc -z -v -w30 opentelemetry-demo-kafka 9092; do echo waiting
            for kafka; sleep 2; done;
          image: busybox:latest
          name: wait-for-kafka
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: opentelemetry-demo-frontend
  annotations:
    harness.io/direct-apply: "true"
    harness.io/track: "canary | stable"
  labels:
    
    opentelemetry.io/name: opentelemetry-demo-frontend
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: frontend
    app.kubernetes.io/name: opentelemetry-demo-frontend
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  selector:
    matchLabels:
      
      opentelemetry.io/name: opentelemetry-demo-frontend
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: opentelemetry-demo-frontend
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: frontend
        app.kubernetes.io/name: opentelemetry-demo-frontend
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: frontend
          image: 'ghcr.io/open-telemetry/demo:1.4.0-frontend'
          imagePullPolicy: IfNotPresent
          ports:
          
          - containerPort: 8080
            name: service
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_K8S_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: OTEL_K8S_NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          - name: OTEL_K8S_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: OTEL_K8S_POD_UID
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.uid
          - name: OTEL_COLLECTOR_NAME
            value: 'opentelemetry-demo-otelcol'
          - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
            value: cumulative
          - name: FRONTEND_PORT
            value: "8080"
          - name: FRONTEND_ADDR
            value: :8080
          - name: AD_SERVICE_ADDR
            value: 'opentelemetry-demo-adservice:8080'
          - name: CART_SERVICE_ADDR
            value: 'opentelemetry-demo-cartservice:8080'
          - name: CHECKOUT_SERVICE_ADDR
            value: 'opentelemetry-demo-checkoutservice:8080'
          - name: CURRENCY_SERVICE_ADDR
            value: 'opentelemetry-demo-currencyservice:8080'
          - name: PRODUCT_CATALOG_SERVICE_ADDR
            value: 'opentelemetry-demo-productcatalogservice:8080'
          - name: RECOMMENDATION_SERVICE_ADDR
            value: 'opentelemetry-demo-recommendationservice:8080'
          - name: SHIPPING_SERVICE_ADDR
            value: 'opentelemetry-demo-shippingservice:8080'
          - name: OTEL_EXPORTER_OTLP_ENDPOINT
            value: http://$(OTEL_COLLECTOR_NAME):4317
          - name: WEB_OTEL_SERVICE_NAME
            value: frontend-web
          - name: PUBLIC_OTEL_EXPORTER_OTLP_TRACES_ENDPOINT
            value: http://localhost:8080/oltp-http/v1/traces
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: service.name=$(OTEL_SERVICE_NAME),service.instance.id=$(OTEL_K8S_POD_UID),service.namespace=opentelemetry-demo,k8s.namespace.name=$(OTEL_K8S_NAMESPACE),k8s.node.name=$(OTEL_K8S_NODE_NAME),k8s.pod.name=$(OTEL_K8S_POD_NAME)
          resources:
            limits:
              memory: 500Mi
          securityContext:
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
---

# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: opentelemetry-demo-kafka
  annotations:
    harness.io/direct-apply: "true"
    harness.io/track: "canary | stable"
  labels:
    
    opentelemetry.io/name: opentelemetry-demo-kafka
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: kafka
    app.kubernetes.io/name: opentelemetry-demo-kafka
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  selector:
    matchLabels:
      
      opentelemetry.io/name: opentelemetry-demo-kafka
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: opentelemetry-demo-kafka
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: kafka
        app.kubernetes.io/name: opentelemetry-demo-kafka
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: kafka
          image: 'ghcr.io/open-telemetry/demo:1.4.0-kafka'
          imagePullPolicy: IfNotPresent
          ports:
          
          - containerPort: 9092
            name: plaintext
          - containerPort: 9093
            name: controller
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_K8S_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: OTEL_K8S_NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          - name: OTEL_K8S_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: OTEL_K8S_POD_UID
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.uid
          - name: OTEL_COLLECTOR_NAME
            value: 'opentelemetry-demo-otelcol'
          - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
            value: cumulative
          - name: KAFKA_ADVERTISED_LISTENERS
            value: PLAINTEXT://opentelemetry-demo-kafka:9092
          - name: OTEL_EXPORTER_OTLP_ENDPOINT
            value: http://$(OTEL_COLLECTOR_NAME):4317
          - name: KAFKA_HEAP_OPTS
            value: -Xmx200M -Xms200M
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: service.name=$(OTEL_SERVICE_NAME),service.instance.id=$(OTEL_K8S_POD_UID),service.namespace=opentelemetry-demo,k8s.namespace.name=$(OTEL_K8S_NAMESPACE),k8s.node.name=$(OTEL_K8S_NODE_NAME),k8s.pod.name=$(OTEL_K8S_POD_NAME)
          resources:
            limits:
              memory: 500Mi
          securityContext:
            runAsGroup: 1000
            runAsNonRoot: true
            runAsUser: 1000
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: opentelemetry-demo-loadgenerator
  annotations:
    harness.io/direct-apply: "true"
    harness.io/track: "canary | stable"
  labels:
    
    opentelemetry.io/name: opentelemetry-demo-loadgenerator
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: loadgenerator
    app.kubernetes.io/name: opentelemetry-demo-loadgenerator
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  selector:
    matchLabels:
      
      opentelemetry.io/name: opentelemetry-demo-loadgenerator
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: opentelemetry-demo-loadgenerator
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: loadgenerator
        app.kubernetes.io/name: opentelemetry-demo-loadgenerator
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: loadgenerator
          image: 'ghcr.io/open-telemetry/demo:1.4.0-loadgenerator'
          imagePullPolicy: IfNotPresent
          ports:
          
          - containerPort: 8089
            name: service
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_K8S_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: OTEL_K8S_NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          - name: OTEL_K8S_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: OTEL_K8S_POD_UID
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.uid
          - name: OTEL_COLLECTOR_NAME
            value: 'opentelemetry-demo-otelcol'
          - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
            value: cumulative
          - name: LOCUST_WEB_PORT
            value: "8089"
          - name: LOCUST_USERS
            value: "10"
          - name: LOCUST_SPAWN_RATE
            value: "1"
          - name: LOCUST_HOST
            value: http://opentelemetry-demo-frontend:8080
          - name: LOCUST_HEADLESS
            value: "false"
          - name: LOCUST_AUTOSTART
            value: "true"
          - name: PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION
            value: python
          - name: OTEL_EXPORTER_OTLP_TRACES_ENDPOINT
            value: http://$(OTEL_COLLECTOR_NAME):4318/v1/traces
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: service.name=$(OTEL_SERVICE_NAME),service.instance.id=$(OTEL_K8S_POD_UID),service.namespace=opentelemetry-demo,k8s.namespace.name=$(OTEL_K8S_NAMESPACE),k8s.node.name=$(OTEL_K8S_NODE_NAME),k8s.pod.name=$(OTEL_K8S_POD_NAME)
          resources:
            limits:
              memory: 320Mi
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: opentelemetry-demo-paymentservice
  annotations:
    harness.io/direct-apply: "true"
    harness.io/track: "canary | stable"
  labels:
    
    opentelemetry.io/name: opentelemetry-demo-paymentservice
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: paymentservice
    app.kubernetes.io/name: opentelemetry-demo-paymentservice
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  selector:
    matchLabels:
      
      opentelemetry.io/name: opentelemetry-demo-paymentservice
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: opentelemetry-demo-paymentservice
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: paymentservice
        app.kubernetes.io/name: opentelemetry-demo-paymentservice
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: paymentservice
          image: 'ghcr.io/open-telemetry/demo:1.4.0-paymentservice'
          imagePullPolicy: IfNotPresent
          ports:
          
          - containerPort: 8080
            name: service
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_K8S_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: OTEL_K8S_NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          - name: OTEL_K8S_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: OTEL_K8S_POD_UID
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.uid
          - name: OTEL_COLLECTOR_NAME
            value: 'opentelemetry-demo-otelcol'
          - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
            value: cumulative
          - name: PAYMENT_SERVICE_PORT
            value: "8080"
          - name: OTEL_EXPORTER_OTLP_ENDPOINT
            value: http://$(OTEL_COLLECTOR_NAME):4317
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: service.name=$(OTEL_SERVICE_NAME),service.instance.id=$(OTEL_K8S_POD_UID),service.namespace=opentelemetry-demo,k8s.namespace.name=$(OTEL_K8S_NAMESPACE),k8s.node.name=$(OTEL_K8S_NODE_NAME),k8s.pod.name=$(OTEL_K8S_POD_NAME)
          resources:
            limits:
              memory: 320Mi
          securityContext:
            runAsGroup: 1000
            runAsNonRoot: true
            runAsUser: 1000
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: opentelemetry-demo-productcatalogservice
  annotations:
    harness.io/direct-apply: "true"
    harness.io/track: "canary | stable"
  labels:
    
    opentelemetry.io/name: opentelemetry-demo-productcatalogservice
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: productcatalogservice
    app.kubernetes.io/name: opentelemetry-demo-productcatalogservice
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  selector:
    matchLabels:
      
      opentelemetry.io/name: opentelemetry-demo-productcatalogservice
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: opentelemetry-demo-productcatalogservice
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: productcatalogservice
        app.kubernetes.io/name: opentelemetry-demo-productcatalogservice
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: productcatalogservice
          image: 'ghcr.io/open-telemetry/demo:1.4.0-productcatalogservice'
          imagePullPolicy: IfNotPresent
          ports:
          
          - containerPort: 8080
            name: service
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_K8S_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: OTEL_K8S_NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          - name: OTEL_K8S_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: OTEL_K8S_POD_UID
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.uid
          - name: OTEL_COLLECTOR_NAME
            value: 'opentelemetry-demo-otelcol'
          - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
            value: cumulative
          - name: PRODUCT_CATALOG_SERVICE_PORT
            value: "8080"
          - name: FEATURE_FLAG_GRPC_SERVICE_ADDR
            value: 'opentelemetry-demo-featureflagservice:50053'
          - name: OTEL_EXPORTER_OTLP_ENDPOINT
            value: http://$(OTEL_COLLECTOR_NAME):4317
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: service.name=$(OTEL_SERVICE_NAME),service.instance.id=$(OTEL_K8S_POD_UID),service.namespace=opentelemetry-demo,k8s.namespace.name=$(OTEL_K8S_NAMESPACE),k8s.node.name=$(OTEL_K8S_NODE_NAME),k8s.pod.name=$(OTEL_K8S_POD_NAME)
          resources:
            limits:
              memory: 320Mi
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: opentelemetry-demo-quoteservice
  annotations:
    harness.io/direct-apply: "true"
    harness.io/track: "canary | stable"
  labels:
    
    opentelemetry.io/name: opentelemetry-demo-quoteservice
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: quoteservice
    app.kubernetes.io/name: opentelemetry-demo-quoteservice
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  selector:
    matchLabels:
      
      opentelemetry.io/name: opentelemetry-demo-quoteservice
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: opentelemetry-demo-quoteservice
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: quoteservice
        app.kubernetes.io/name: opentelemetry-demo-quoteservice
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: quoteservice
          image: 'ghcr.io/open-telemetry/demo:1.4.0-quoteservice'
          imagePullPolicy: IfNotPresent
          ports:
          
          - containerPort: 8080
            name: service
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_K8S_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: OTEL_K8S_NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          - name: OTEL_K8S_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: OTEL_K8S_POD_UID
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.uid
          - name: OTEL_COLLECTOR_NAME
            value: 'opentelemetry-demo-otelcol'
          - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
            value: cumulative
          - name: QUOTE_SERVICE_PORT
            value: "8080"
          - name: OTEL_PHP_AUTOLOAD_ENABLED
            value: "true"
          - name: OTEL_EXPORTER_OTLP_ENDPOINT
            value: http://$(OTEL_COLLECTOR_NAME):4318
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: service.name=$(OTEL_SERVICE_NAME),service.instance.id=$(OTEL_K8S_POD_UID),service.namespace=opentelemetry-demo,k8s.namespace.name=$(OTEL_K8S_NAMESPACE),k8s.node.name=$(OTEL_K8S_NODE_NAME),k8s.pod.name=$(OTEL_K8S_POD_NAME)
          resources:
            limits:
              memory: 240Mi
          securityContext:
            runAsGroup: 33
            runAsNonRoot: true
            runAsUser: 33
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: opentelemetry-demo-recommendationservice
  annotations:
    harness.io/direct-apply: "true"
    harness.io/track: "canary | stable"
  labels:
    
    opentelemetry.io/name: opentelemetry-demo-recommendationservice
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: recommendationservice
    app.kubernetes.io/name: opentelemetry-demo-recommendationservice
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  selector:
    matchLabels:
      
      opentelemetry.io/name: opentelemetry-demo-recommendationservice
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: opentelemetry-demo-recommendationservice
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: recommendationservice
        app.kubernetes.io/name: opentelemetry-demo-recommendationservice
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: recommendationservice
          image: 'ghcr.io/open-telemetry/demo:1.4.0-recommendationservice'
          imagePullPolicy: IfNotPresent
          ports:
          
          - containerPort: 8080
            name: service
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_K8S_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: OTEL_K8S_NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          - name: OTEL_K8S_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: OTEL_K8S_POD_UID
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.uid
          - name: OTEL_COLLECTOR_NAME
            value: 'opentelemetry-demo-otelcol'
          - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
            value: cumulative
          - name: RECOMMENDATION_SERVICE_PORT
            value: "8080"
          - name: PRODUCT_CATALOG_SERVICE_ADDR
            value: 'opentelemetry-demo-productcatalogservice:8080'
          - name: FEATURE_FLAG_GRPC_SERVICE_ADDR
            value: 'opentelemetry-demo-featureflagservice:50053'
          - name: OTEL_PYTHON_LOG_CORRELATION
            value: "true"
          - name: PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION
            value: python
          - name: OTEL_EXPORTER_OTLP_ENDPOINT
            value: http://$(OTEL_COLLECTOR_NAME):4317
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: service.name=$(OTEL_SERVICE_NAME),service.instance.id=$(OTEL_K8S_POD_UID),service.namespace=opentelemetry-demo,k8s.namespace.name=$(OTEL_K8S_NAMESPACE),k8s.node.name=$(OTEL_K8S_NODE_NAME),k8s.pod.name=$(OTEL_K8S_POD_NAME)
          resources:
            limits:
              memory: 500Mi
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: opentelemetry-demo-redis
  annotations:
    harness.io/direct-apply: "true"
    harness.io/track: "canary | stable"
  labels:
    
    opentelemetry.io/name: opentelemetry-demo-redis
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: redis
    app.kubernetes.io/name: opentelemetry-demo-redis
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  selector:
    matchLabels:
      
      opentelemetry.io/name: opentelemetry-demo-redis
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: opentelemetry-demo-redis
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: redis
        app.kubernetes.io/name: opentelemetry-demo-redis
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: redis
          image: 'redis:alpine'
          imagePullPolicy: IfNotPresent
          ports:
          
          - containerPort: 6379
            name: redis
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_K8S_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: OTEL_K8S_NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          - name: OTEL_K8S_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: OTEL_K8S_POD_UID
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.uid
          - name: OTEL_COLLECTOR_NAME
            value: 'opentelemetry-demo-otelcol'
          - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
            value: cumulative
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: service.name=$(OTEL_SERVICE_NAME),service.instance.id=$(OTEL_K8S_POD_UID),service.namespace=opentelemetry-demo,k8s.namespace.name=$(OTEL_K8S_NAMESPACE),k8s.node.name=$(OTEL_K8S_NODE_NAME),k8s.pod.name=$(OTEL_K8S_POD_NAME)
          resources:
            limits:
              memory: 320Mi
          securityContext:
            runAsGroup: 1000
            runAsNonRoot: true
            runAsUser: 999
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: opentelemetry-demo-shippingservice
  annotations:
    harness.io/direct-apply: "true"
    harness.io/track: "canary | stable"
  labels:
    
    opentelemetry.io/name: opentelemetry-demo-shippingservice
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: shippingservice
    app.kubernetes.io/name: opentelemetry-demo-shippingservice
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
spec:
  selector:
    matchLabels:
      
      opentelemetry.io/name: opentelemetry-demo-shippingservice
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: opentelemetry-demo-shippingservice
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: shippingservice
        app.kubernetes.io/name: opentelemetry-demo-shippingservice
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: shippingservice
          image: 'ghcr.io/open-telemetry/demo:1.4.0-shippingservice'
          imagePullPolicy: IfNotPresent
          ports:
          
          - containerPort: 8080
            name: service
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_K8S_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: OTEL_K8S_NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          - name: OTEL_K8S_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: OTEL_K8S_POD_UID
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.uid
          - name: OTEL_COLLECTOR_NAME
            value: 'opentelemetry-demo-otelcol'
          - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
            value: cumulative
          - name: SHIPPING_SERVICE_PORT
            value: "8080"
          - name: QUOTE_SERVICE_ADDR
            value: http://opentelemetry-demo-quoteservice:8080
          - name: OTEL_EXPORTER_OTLP_TRACES_ENDPOINT
            value: http://$(OTEL_COLLECTOR_NAME):4317/v1/traces
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: service.name=$(OTEL_SERVICE_NAME),service.instance.id=$(OTEL_K8S_POD_UID),service.namespace=opentelemetry-demo,k8s.namespace.name=$(OTEL_K8S_NAMESPACE),k8s.node.name=$(OTEL_K8S_NODE_NAME),k8s.pod.name=$(OTEL_K8S_POD_NAME)
          resources:
            limits:
              memory: 320Mi
